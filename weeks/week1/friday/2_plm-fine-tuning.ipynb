{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning protein language models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6.** Describe the problem of predicting the subcellular location of (prokaryotic) proteins as described in [Moreno et al., 2024](https://doi.org/10.1093/bioinformatics/btae677)? Think of a biological question one could answer with proteome-wide predictions of subcellular location, and potential follow-up experiments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/course/anaconda3/lib/python3.11/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/course/anaconda3/lib/python3.11/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd, sklearn.preprocessing\n",
    "import datasets, evaluate, transformers # Hugging Face libraries https://doi.org/10.18653/v1/2020.emnlp-demos.6\n",
    "import Bio.SeqIO.FastaIO # Biopython for reading fasta files\n",
    "from IPython.display import display, HTML\n",
    "random_number = 4 # https://xkcd.com/221/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 5492k  100 5492k    0     0  10.3M      0 --:--:-- --:--:-- --:--:-- 10.3M\n"
     ]
    }
   ],
   "source": [
    "# Uncomment & execute once to download data from https://services.healthtech.dtu.dk/services/DeepLocPro-1.0/\n",
    "!mkdir -p data\n",
    "!curl https://services.healthtech.dtu.dk/services/DeepLocPro-1.0/data/graphpart_set.fasta -o data/graphpart_set.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7.** Look at the contents of `df_data`, how was the column `fold_id` defined in the paper? What exact set of sequences are in this data set (check number of rows)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot_id</th>\n",
       "      <th>subcellular_location</th>\n",
       "      <th>organism_group</th>\n",
       "      <th>fold_id</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8560</th>\n",
       "      <td>Q8A0Z3</td>\n",
       "      <td>Cytoplasmic</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>MAVTMADITKLRKMTGAGMMDCKNALTEAEGDYDKAMEIIRKKGQA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8568</th>\n",
       "      <td>Q8A2N8</td>\n",
       "      <td>Cytoplasmic</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>MIMSKETLIKSIREIPDFPIPGILFYDVTTLFKDPWCLQELSNIMF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593</th>\n",
       "      <td>P32709</td>\n",
       "      <td>CYtoplasmicMembrane</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>MTQTSAFHFESLVWDWPIAIYLFLIGISAGLVTLAVLLRRFYPQAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>E7FHF8</td>\n",
       "      <td>Cytoplasmic</td>\n",
       "      <td>archaea</td>\n",
       "      <td>0</td>\n",
       "      <td>MKLGVFELTDCGGCALNLLFLYDKLLDLLEFYEIAEFHMATSKKSR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>E7FHU4</td>\n",
       "      <td>Cytoplasmic</td>\n",
       "      <td>archaea</td>\n",
       "      <td>0</td>\n",
       "      <td>MGKVRIGFYALTSCYGCQLQLAMMDELLQLIPNAEIVCWFMIDRDS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5239</th>\n",
       "      <td>Q97F85</td>\n",
       "      <td>Cytoplasmic</td>\n",
       "      <td>positive</td>\n",
       "      <td>4</td>\n",
       "      <td>MRKLFTSESVTEGHPDKICDQISDAILDAILEKDPNGRVACETTVT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>P33656</td>\n",
       "      <td>Cytoplasmic</td>\n",
       "      <td>positive</td>\n",
       "      <td>4</td>\n",
       "      <td>MKNKTEVKNGGEKKNSKKVSKEESAKEKNEKMKIVKNLIDKGKKSG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11894</th>\n",
       "      <td>P13949</td>\n",
       "      <td>OuterMembrane</td>\n",
       "      <td>negative</td>\n",
       "      <td>4</td>\n",
       "      <td>MCALDRRERPLNSQSVNKYILNVQNIYRNSPVPVCVRNKNRKILYA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11890</th>\n",
       "      <td>P42185</td>\n",
       "      <td>Extracellular</td>\n",
       "      <td>negative</td>\n",
       "      <td>4</td>\n",
       "      <td>MRLRFSVPLFFFGCVFVHGVFAGPFPPPGMSLPEYWGEEHVWWDGR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11902</th>\n",
       "      <td>Q0P986</td>\n",
       "      <td>OuterMembrane</td>\n",
       "      <td>negative</td>\n",
       "      <td>4</td>\n",
       "      <td>MKTRFSLILSACLLSSSLFAKNTDDEITKLQKQLAQIQAELAQIRK...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11906 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      uniprot_id subcellular_location organism_group  fold_id  \\\n",
       "8560      Q8A0Z3          Cytoplasmic       negative        0   \n",
       "8568      Q8A2N8          Cytoplasmic       negative        0   \n",
       "2593      P32709  CYtoplasmicMembrane       negative        0   \n",
       "61        E7FHF8          Cytoplasmic        archaea        0   \n",
       "63        E7FHU4          Cytoplasmic        archaea        0   \n",
       "...          ...                  ...            ...      ...   \n",
       "5239      Q97F85          Cytoplasmic       positive        4   \n",
       "5226      P33656          Cytoplasmic       positive        4   \n",
       "11894     P13949        OuterMembrane       negative        4   \n",
       "11890     P42185        Extracellular       negative        4   \n",
       "11902     Q0P986        OuterMembrane       negative        4   \n",
       "\n",
       "                                                sequence  \n",
       "8560   MAVTMADITKLRKMTGAGMMDCKNALTEAEGDYDKAMEIIRKKGQA...  \n",
       "8568   MIMSKETLIKSIREIPDFPIPGILFYDVTTLFKDPWCLQELSNIMF...  \n",
       "2593   MTQTSAFHFESLVWDWPIAIYLFLIGISAGLVTLAVLLRRFYPQAG...  \n",
       "61     MKLGVFELTDCGGCALNLLFLYDKLLDLLEFYEIAEFHMATSKKSR...  \n",
       "63     MGKVRIGFYALTSCYGCQLQLAMMDELLQLIPNAEIVCWFMIDRDS...  \n",
       "...                                                  ...  \n",
       "5239   MRKLFTSESVTEGHPDKICDQISDAILDAILEKDPNGRVACETTVT...  \n",
       "5226   MKNKTEVKNGGEKKNSKKVSKEESAKEKNEKMKIVKNLIDKGKKSG...  \n",
       "11894  MCALDRRERPLNSQSVNKYILNVQNIYRNSPVPVCVRNKNRKILYA...  \n",
       "11890  MRLRFSVPLFFFGCVFVHGVFAGPFPPPGMSLPEYWGEEHVWWDGR...  \n",
       "11902  MKTRFSLILSACLLSSSLFAKNTDDEITKLQKQLAQIQAELAQIRK...  \n",
       "\n",
       "[11906 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/graphpart_set.fasta') as handle:\n",
    "    fasta_cols = ['header', 'sequence']\n",
    "    df_data = pd.DataFrame.from_records([values for values in Bio.SeqIO.FastaIO.SimpleFastaParser(handle)], columns=fasta_cols)\n",
    "header_cols = ['uniprot_id', 'subcellular_location', 'organism_group', 'fold_id']\n",
    "df_data[header_cols] = df_data['header'].str.split('|', expand=True)\n",
    "final_cols = ['uniprot_id']\n",
    "df_data = df_data[['uniprot_id', 'subcellular_location', 'organism_group', 'fold_id', 'sequence']].astype({'fold_id': int}).sort_values('fold_id')\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot_id</th>\n",
       "      <th>subcellular_location</th>\n",
       "      <th>organism_group</th>\n",
       "      <th>fold_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8560</th>\n",
       "      <td>Q8A0Z3</td>\n",
       "      <td>Cytoplasmic</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>MAVTMADITKLRKMTGAGMMDCKNALTEAEGDYDKAMEIIRKKGQA...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8568</th>\n",
       "      <td>Q8A2N8</td>\n",
       "      <td>Cytoplasmic</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>MIMSKETLIKSIREIPDFPIPGILFYDVTTLFKDPWCLQELSNIMF...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593</th>\n",
       "      <td>P32709</td>\n",
       "      <td>CYtoplasmicMembrane</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>MTQTSAFHFESLVWDWPIAIYLFLIGISAGLVTLAVLLRRFYPQAG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>E7FHF8</td>\n",
       "      <td>Cytoplasmic</td>\n",
       "      <td>archaea</td>\n",
       "      <td>0</td>\n",
       "      <td>MKLGVFELTDCGGCALNLLFLYDKLLDLLEFYEIAEFHMATSKKSR...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>E7FHU4</td>\n",
       "      <td>Cytoplasmic</td>\n",
       "      <td>archaea</td>\n",
       "      <td>0</td>\n",
       "      <td>MGKVRIGFYALTSCYGCQLQLAMMDELLQLIPNAEIVCWFMIDRDS...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5239</th>\n",
       "      <td>Q97F85</td>\n",
       "      <td>Cytoplasmic</td>\n",
       "      <td>positive</td>\n",
       "      <td>4</td>\n",
       "      <td>MRKLFTSESVTEGHPDKICDQISDAILDAILEKDPNGRVACETTVT...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>P33656</td>\n",
       "      <td>Cytoplasmic</td>\n",
       "      <td>positive</td>\n",
       "      <td>4</td>\n",
       "      <td>MKNKTEVKNGGEKKNSKKVSKEESAKEKNEKMKIVKNLIDKGKKSG...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11894</th>\n",
       "      <td>P13949</td>\n",
       "      <td>OuterMembrane</td>\n",
       "      <td>negative</td>\n",
       "      <td>4</td>\n",
       "      <td>MCALDRRERPLNSQSVNKYILNVQNIYRNSPVPVCVRNKNRKILYA...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11890</th>\n",
       "      <td>P42185</td>\n",
       "      <td>Extracellular</td>\n",
       "      <td>negative</td>\n",
       "      <td>4</td>\n",
       "      <td>MRLRFSVPLFFFGCVFVHGVFAGPFPPPGMSLPEYWGEEHVWWDGR...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11902</th>\n",
       "      <td>Q0P986</td>\n",
       "      <td>OuterMembrane</td>\n",
       "      <td>negative</td>\n",
       "      <td>4</td>\n",
       "      <td>MKTRFSLILSACLLSSSLFAKNTDDEITKLQKQLAQIQAELAQIRK...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11906 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      uniprot_id subcellular_location organism_group  fold_id  \\\n",
       "8560      Q8A0Z3          Cytoplasmic       negative        0   \n",
       "8568      Q8A2N8          Cytoplasmic       negative        0   \n",
       "2593      P32709  CYtoplasmicMembrane       negative        0   \n",
       "61        E7FHF8          Cytoplasmic        archaea        0   \n",
       "63        E7FHU4          Cytoplasmic        archaea        0   \n",
       "...          ...                  ...            ...      ...   \n",
       "5239      Q97F85          Cytoplasmic       positive        4   \n",
       "5226      P33656          Cytoplasmic       positive        4   \n",
       "11894     P13949        OuterMembrane       negative        4   \n",
       "11890     P42185        Extracellular       negative        4   \n",
       "11902     Q0P986        OuterMembrane       negative        4   \n",
       "\n",
       "                                                sequence  label  \n",
       "8560   MAVTMADITKLRKMTGAGMMDCKNALTEAEGDYDKAMEIIRKKGQA...      2  \n",
       "8568   MIMSKETLIKSIREIPDFPIPGILFYDVTTLFKDPWCLQELSNIMF...      2  \n",
       "2593   MTQTSAFHFESLVWDWPIAIYLFLIGISAGLVTLAVLLRRFYPQAG...      0  \n",
       "61     MKLGVFELTDCGGCALNLLFLYDKLLDLLEFYEIAEFHMATSKKSR...      2  \n",
       "63     MGKVRIGFYALTSCYGCQLQLAMMDELLQLIPNAEIVCWFMIDRDS...      2  \n",
       "...                                                  ...    ...  \n",
       "5239   MRKLFTSESVTEGHPDKICDQISDAILDAILEKDPNGRVACETTVT...      2  \n",
       "5226   MKNKTEVKNGGEKKNSKKVSKEESAKEKNEKMKIVKNLIDKGKKSG...      2  \n",
       "11894  MCALDRRERPLNSQSVNKYILNVQNIYRNSPVPVCVRNKNRKILYA...      4  \n",
       "11890  MRLRFSVPLFFFGCVFVHGVFAGPFPPPGMSLPEYWGEEHVWWDGR...      3  \n",
       "11902  MKTRFSLILSACLLSSSLFAKNTDDEITKLQKQLAQIQAELAQIRK...      4  \n",
       "\n",
       "[11906 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode subcellular location as numerical labels\n",
    "subcellular_location_encoder = sklearn.preprocessing.LabelEncoder()\n",
    "subcellular_location_encoder.fit(df_data['subcellular_location'])\n",
    "df_data['label'] = subcellular_location_encoder.transform(df_data['subcellular_location'])\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8.** How were the data partitioned during training and evaluation in the paper? What does the code below do, and how does it compare to the approach taken in the paper?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7336 records in training data:\n",
      "subcellular_location\n",
      "Cytoplasmic            4345\n",
      "CYtoplasmicMembrane    1534\n",
      "Extracellular           645\n",
      "OuterMembrane           433\n",
      "Periplasmic             320\n",
      "Cellwall                 59\n",
      "Name: count, dtype: int64\n",
      "\n",
      "2579 records in eval data:\n",
      "subcellular_location\n",
      "Cytoplasmic            1568\n",
      "CYtoplasmicMembrane     476\n",
      "Extracellular           224\n",
      "OuterMembrane           159\n",
      "Periplasmic             136\n",
      "Cellwall                 16\n",
      "Name: count, dtype: int64\n",
      "\n",
      "1991 records in test data:\n",
      "subcellular_location\n",
      "Cytoplasmic            972\n",
      "CYtoplasmicMembrane    525\n",
      "Extracellular          208\n",
      "OuterMembrane          164\n",
      "Periplasmic            110\n",
      "Cellwall                12\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_id = {0, 1, 2}\n",
    "eval_id = {3}\n",
    "test_id = {4}\n",
    "\n",
    "df_train = df_data.query('fold_id in @train_id')#.groupby('subcellular_location').sample(n=50, random_state=random_number)\n",
    "df_eval = df_data.query('fold_id in @eval_id')\n",
    "df_test = df_data.query('fold_id in @test_id')\n",
    "print(len(df_train), 'records in training data:')\n",
    "print(df_train['subcellular_location'].value_counts())\n",
    "print()\n",
    "print(len(df_eval), 'records in eval data:')\n",
    "print(df_eval['subcellular_location'].value_counts())\n",
    "print()\n",
    "print(len(df_test), 'records in test data:')\n",
    "print(df_test['subcellular_location'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare train/eval/test data sets for ESM2 model\n",
    "model_checkpoint = 'facebook/esm2_t6_8M_UR50D'\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "train_tokenized = tokenizer(df_train['sequence'].tolist(), truncation=True, max_length=1024)\n",
    "eval_tokenized = tokenizer(df_eval['sequence'].tolist(), truncation=True, max_length=1024)\n",
    "test_tokenized = tokenizer(df_test['sequence'].tolist(), truncation=True, max_length=1024)\n",
    "\n",
    "train_dataset = datasets.Dataset.from_dict(train_tokenized).add_column('labels', df_train['label'].tolist())\n",
    "eval_dataset = datasets.Dataset.from_dict(eval_tokenized).add_column('labels', df_eval['label'].tolist())\n",
    "test_dataset = datasets.Dataset.from_dict(test_tokenized).add_column('labels', df_test['label'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9.** There's a warning about uninitialized weights when loading the ESM-2 model using `AutoModelForSequenceClassification` below. Describe the part of the network that has the uninitialized weights. How does the new part connect to the rest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmForSequenceClassification were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EsmForSequenceClassification(\n",
       "  (esm): EsmModel(\n",
       "    (embeddings): EsmEmbeddings(\n",
       "      (word_embeddings): Embedding(33, 320, padding_idx=1)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (position_embeddings): Embedding(1026, 320, padding_idx=1)\n",
       "    )\n",
       "    (encoder): EsmEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "              (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "              (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (emb_layer_norm_after): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (contact_head): EsmContactPredictionHead(\n",
       "      (regression): Linear(in_features=120, out_features=1, bias=True)\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (classifier): EsmClassificationHead(\n",
       "    (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (out_proj): Linear(in_features=320, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=df_data['label'].nunique())\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track accuracy and macro F1 score throughout the training\n",
    "# https://huggingface.co/docs/transformers/en/training#evaluate\n",
    "metric_accuracy = evaluate.load('accuracy')\n",
    "metric_f1 = evaluate.load('f1')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    return {\n",
    "        'accuracy': metric_accuracy.compute(predictions=predictions, references=labels)['accuracy'],\n",
    "        'f1_macro': metric_f1.compute(predictions=predictions, references=labels, average='macro')['f1'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10.** The fine-tuning may fail by running out of GPU memory. Look up `per_device_train_batch_size` and `per_device_eval_batch_size` in the [TrainingArguments docs](https://huggingface.co/docs/transformers/v4.49.0/en/main_classes/trainer#transformers.TrainingArguments). How would you adjust these parameters to use less GPU memory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3632283/3170388540.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = transformers.Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5502' max='5502' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5502/5502 08:34, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.481000</td>\n",
       "      <td>0.601212</td>\n",
       "      <td>0.840248</td>\n",
       "      <td>0.596726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.318100</td>\n",
       "      <td>0.556864</td>\n",
       "      <td>0.869329</td>\n",
       "      <td>0.661516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.223500</td>\n",
       "      <td>0.506299</td>\n",
       "      <td>0.892594</td>\n",
       "      <td>0.748260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up fine-tuning\n",
    "trainer_args = transformers.TrainingArguments(\n",
    "    output_dir=f'{model_checkpoint}-subcellular_location',\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='accuracy',\n",
    "    # Adjust if needed\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model,\n",
    "    trainer_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "retrained = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.6636393666267395,\n",
       " 'test_accuracy': 0.8684078352586639,\n",
       " 'test_f1_macro': 0.725740715595571,\n",
       " 'test_runtime': 12.51,\n",
       " 'test_samples_per_second': 159.153,\n",
       " 'test_steps_per_second': 39.808}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use fine-tuned model to predict on held-out test data\n",
    "retrained_predict = trainer.predict(test_dataset=test_dataset)\n",
    "retrained_predict.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8684078352586639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 2, 4, ..., 2, 5, 4])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert probabilities into discrete predictions by taking the max probability\n",
    "test_labels = np.argmax(retrained_predict.predictions, axis=-1)\n",
    "# Sanity-check by manualy calculating the accuracy\n",
    "print(sum(test_labels == test_dataset['labels']) / len(test_dataset))\n",
    "test_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q11.** Adjust the code below to re-produce the cross-validation results as in Table 2 of the paper. Fine-tune+test separately on every fold, and gather the results in `predicted_labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2, 3, 4} 1 0 6668 2684 2554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3632283/393074312.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = transformers.Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3566' max='5001' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3566/5001 05:21 < 02:09, 11.07 it/s, Epoch 2.14/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.073800</td>\n",
       "      <td>0.025715</td>\n",
       "      <td>0.993294</td>\n",
       "      <td>0.986395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.042800</td>\n",
       "      <td>0.013498</td>\n",
       "      <td>0.995529</td>\n",
       "      <td>0.986367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fold_id = set(df_data.fold_id)\n",
    "predicted_labels = []\n",
    "\n",
    "def weight_reset(m):\n",
    "    reset_parameters = getattr(m, \"reset_parameters\", None)\n",
    "    if callable(reset_parameters):\n",
    "        m.reset_parameters()\n",
    "\n",
    "        \n",
    "for test_id in sorted(fold_id):\n",
    "    eval_id = (test_id + 1) % 5\n",
    "    train_id = fold_id - set([eval_id, test_id])\n",
    "\n",
    "    df_train = df_data.query('fold_id in @train_id')#.groupby('subcellular_location').sample(n=10, random_state=random_number)\n",
    "    df_eval = df_data.query('fold_id == @eval_id')\n",
    "    df_test = df_data.query('fold_id == @test_id')\n",
    "    print(train_id, eval_id, test_id, len(df_train), len(df_eval), len(df_test))\n",
    "\n",
    "    # ...\n",
    "    train_tokenized = tokenizer(df_train['sequence'].tolist(), truncation=True, max_length=1024)\n",
    "    eval_tokenized = tokenizer(df_eval['sequence'].tolist(), truncation=True, max_length=1024)\n",
    "    test_tokenized = tokenizer(df_test['sequence'].tolist(), truncation=True, max_length=1024)\n",
    "    \n",
    "    train_dataset = datasets.Dataset.from_dict(train_tokenized).add_column('labels', df_train['label'].tolist())\n",
    "    eval_dataset = datasets.Dataset.from_dict(eval_tokenized).add_column('labels', df_eval['label'].tolist())\n",
    "    test_dataset = datasets.Dataset.from_dict(test_tokenized).add_column('labels', df_test['label'].tolist())\n",
    "    model = transformers.AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=df_data['label'].nunique())\n",
    "    weight_reset(model)\n",
    "    trainer = transformers.Trainer(\n",
    "        model,\n",
    "        trainer_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "    # Predict labels, and gather the predictions for the held-out test data into predicted_labels\n",
    "    retrained_predict = trainer.predict(test_dataset=test_dataset)\n",
    "    predicted_labels += list(np.argmax(retrained_predict.predictions, axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q12.** Discuss differences between the methodology and the resulting performance of the approach taken in the paper, and the reproduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>Archaea</th>\n",
       "      <th>Gram pos</th>\n",
       "      <th>Gram neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>size</th>\n",
       "      <td>11906</td>\n",
       "      <td>283</td>\n",
       "      <td>3206</td>\n",
       "      <td>8417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_macro</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Overall Archaea Gram pos Gram neg\n",
       "size       11906     283     3206     8417\n",
       "accuracy    0.96    0.95     0.96     0.96\n",
       "f1_macro    0.89    0.73     0.59     0.91"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show table with performance metrics split by organism to match Table 2\n",
    "def calculate_stats_(df):\n",
    "    accuracy = metric_accuracy.compute(predictions=df.predicted_labels.values, references=df.label.values)['accuracy']\n",
    "    f1_macro = metric_f1.compute(predictions=df.predicted_labels.values, references=df.label.values, average='macro')['f1']\n",
    "    return pd.Series({\n",
    "        'size': '{:d}'.format(len(df)),\n",
    "        'accuracy': '{:.2f}'.format(accuracy),\n",
    "        'f1_macro': '{:.2f}'.format(f1_macro),\n",
    "    })\n",
    "\n",
    "df_data['predicted_labels'] = predicted_labels\n",
    "pd.concat([\n",
    "    calculate_stats_(df_data),\n",
    "    calculate_stats_(df_data.query('organism_group == \"archaea\"')),\n",
    "    calculate_stats_(df_data.query('organism_group == \"positive\"')),\n",
    "    calculate_stats_(df_data.query('organism_group == \"negative\"')),\n",
    "], axis=1).set_axis(['Overall', 'Archaea' , 'Gram pos', 'Gram neg'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
